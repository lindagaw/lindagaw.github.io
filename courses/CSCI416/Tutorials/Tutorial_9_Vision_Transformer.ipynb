{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b885f0b",
   "metadata": {},
   "source": [
    "### Warning: Running this on your local/personal laptop will be super slow and likely to destroy your battery. \n",
    "### Run on on a GPU provided by the CS department instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee90da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures compatibility for Python 2 and 3 print function\n",
    "from __future__ import print_function\n",
    "\n",
    "# Core PyTorch libraries for tensor and neural network operations\n",
    "import torch\n",
    "import torch.nn as nn  # Neural network module in PyTorch\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import torch.nn.functional as F  # Functional interface with activation functions, loss functions, etc.\n",
    "import torch.backends.cudnn as cudnn  # CUDNN backend to optimize deep learning operations on GPUs\n",
    "\n",
    "# Numerical operations library\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch library for vision-related utilities\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms  # Transformations that can be applied to image data\n",
    "\n",
    "# Standard Python libraries for system operations, argument parsing, and data handling\n",
    "import os  # Interfaces with the operating system\n",
    "import argparse  # Parser for command-line options, arguments, and sub-commands\n",
    "import pandas as pd  # Data analysis and manipulation tool\n",
    "import csv  # CSV file reading and writing\n",
    "import time  # Time access and conversions\n",
    "\n",
    "# Importing custom modules that are presumably part of the user's project\n",
    "from models import *  # This would import all available models in the models directory\n",
    "from utils import progress_bar  # Likely a utility to display a progress bar in the console\n",
    "from randomaug import RandAugment  # Custom module for random data augmentation\n",
    "from models.vit import ViT  # Importing the Vision Transformer model from the models directory\n",
    "from models.convmixer import ConvMixer  # Importing the ConvMixer model from the models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the argparse library, which is used to create user-friendly command-line interfaces.\n",
    "import argparse\n",
    "\n",
    "# Set up a parser for the command-line arguments.\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "\n",
    "# Add command-line options to the parser. Each option can alter how the training script behaves.\n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='learning rate')  # Set the default learning rate for the optimizer.\n",
    "parser.add_argument('--opt', default=\"adam\")  # Choose the optimizer to use; default is Adam.\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')  # Flag to resume training from a checkpoint if provided.\n",
    "parser.add_argument('--noaug', action='store_true', help='disable use randomaug')  # Flag to disable random augmentations.\n",
    "parser.add_argument('--noamp', action='store_true', help='disable mixed precision training. for older pytorch versions')  # Flag to disable automatic mixed precision training.\n",
    "parser.add_argument('--nowandb', action='store_true', help='disable wandb')  # Flag to disable Weights & Biases logging.\n",
    "parser.add_argument('--mixup', action='store_true', help='add mixup augmentations')  # Flag to enable mixup augmentations.\n",
    "parser.add_argument('--net', default='vit')  # Specify the network architecture to use; default is Vision Transformer (ViT).\n",
    "parser.add_argument('--bs', default='512')  # Set the default batch size for training.\n",
    "parser.add_argument('--size', default=\"32\")  # Define the size of the images used for training.\n",
    "parser.add_argument('--n_epochs', type=int, default='200')  # Set the number of epochs for which to train.\n",
    "parser.add_argument('--patch', default='4', type=int, help=\"patch size for ViT\")  # Specify the patch size for the Vision Transformer.\n",
    "parser.add_argument('--dimhead', default=\"512\", type=int)  # Define the dimension of the heads in the transformer model.\n",
    "parser.add_argument('--convkernel', default='8', type=int, help=\"kernel size parameter for ConvMixer\")  # Set the kernel size for the ConvMixer model.\n",
    "\n",
    "# Parse the command-line arguments.\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Process the parsed arguments.\n",
    "usewandb = not args.nowandb  # Determine whether to use Weights & Biases logging.\n",
    "if usewandb:\n",
    "    import wandb  # Import the wandb library if it is going to be used.\n",
    "    # Set up a watermark identifier for the Weights & Biases logging.\n",
    "    watermark = \"{}_lr{}\".format(args.net, args.lr)\n",
    "    wandb.init(project=\"cifar10-challenge\", name=watermark)  # Initialize the Weights & Biases project.\n",
    "    wandb.config.update(args)  # Update the Weights & Biases configuration with the arguments.\n",
    "\n",
    "# Convert batch size and image size arguments to integers from strings.\n",
    "bs = int(args.bs)\n",
    "imsize = int(args.size)\n",
    "\n",
    "# Set a flag for using automatic mixed precision training.\n",
    "use_amp = not args.noamp\n",
    "# Set a flag for using augmentations.\n",
    "aug = not args.noaug\n",
    "\n",
    "# Determine the device to use for training: 'cuda' for GPU (if available) or 'cpu' for CPU.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # Initialize a variable to keep track of the best test accuracy.\n",
    "start_epoch = 0  # Set the starting epoch, which will be 0 unless a checkpoint is loaded to resume training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fe94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation message.\n",
    "print('==> Preparing data..')\n",
    "\n",
    "# Set the image size based on the network type; different networks may require different input sizes.\n",
    "if args.net == \"vit_timm\":\n",
    "    size = 384  # Vision Transformer (ViT) from the 'timm' library may expect a larger input size.\n",
    "else:\n",
    "    size = imsize  # For other networks, use the size provided as an argument.\n",
    "\n",
    "# Define transformations for the training data.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop the images to 32x32 pixels after padding the edges by 4 pixels.\n",
    "    transforms.Resize(size),  # Resize the images to the specified size.\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally.\n",
    "    transforms.ToTensor(),  # Convert the PIL Image to a PyTorch tensor.\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize the images with mean and std deviation for CIFAR10.\n",
    "])\n",
    "\n",
    "# Define transformations for the testing data (without random augmentations).\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size),  # Resize the images to the specified size.\n",
    "    transforms.ToTensor(),  # Convert the PIL Image to a PyTorch tensor.\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize the images.\n",
    "])\n",
    "\n",
    "# Add RandAugment only if augmentations are enabled.\n",
    "if aug:\n",
    "    N = 2; M = 14  # Define the number and magnitude of the augmentations.\n",
    "    transform_train.transforms.insert(0, RandAugment(N, M))  # Insert RandAugment at the beginning of the transformation pipeline.\n",
    "\n",
    "# Load the CIFAR10 dataset for training and apply the transformations.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)  # Create a DataLoader for the training set.\n",
    "\n",
    "# Load the CIFAR10 dataset for testing and apply the transformations.\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)  # Create a DataLoader for the test set.\n",
    "\n",
    "# Define the class names for CIFAR10 dataset.\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672321ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model factory..\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "if args.net=='res18':\n",
    "    net = ResNet18()\n",
    "elif args.net=='vgg':\n",
    "    net = VGG('VGG19')\n",
    "elif args.net=='res34':\n",
    "    net = ResNet34()\n",
    "elif args.net=='res50':\n",
    "    net = ResNet50()\n",
    "elif args.net=='res101':\n",
    "    net = ResNet101()\n",
    "elif args.net==\"convmixer\":\n",
    "    # from paper, accuracy >96%. you can tune the depth and dim to scale accuracy and speed.\n",
    "    net = ConvMixer(256, 16, kernel_size=args.convkernel, patch_size=1, n_classes=10)\n",
    "elif args.net==\"mlpmixer\":\n",
    "    from models.mlpmixer import MLPMixer\n",
    "    net = MLPMixer(\n",
    "    image_size = 32,\n",
    "    channels = 3,\n",
    "    patch_size = args.patch,\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    num_classes = 10\n",
    ")\n",
    "elif args.net==\"vit_small\":\n",
    "    from models.vit_small import ViT\n",
    "    net = ViT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "elif args.net==\"vit_tiny\":\n",
    "    from models.vit_small import ViT\n",
    "    net = ViT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 4,\n",
    "    heads = 6,\n",
    "    mlp_dim = 256,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "elif args.net==\"simplevit\":\n",
    "    from models.simplevit import SimpleViT\n",
    "    net = SimpleViT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "elif args.net==\"vit\":\n",
    "    # ViT for cifar10\n",
    "    net = ViT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "elif args.net==\"vit_timm\":\n",
    "    import timm\n",
    "    net = timm.create_model(\"vit_base_patch16_384\", pretrained=True)\n",
    "    net.head = nn.Linear(net.head.in_features, 10)\n",
    "elif args.net==\"cait\":\n",
    "    from models.cait import CaiT\n",
    "    net = CaiT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 6,   # depth of transformer for patch to patch attention only\n",
    "    cls_depth=2, # depth of cross attention of CLS tokens to patch\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    layer_dropout = 0.05\n",
    ")\n",
    "elif args.net==\"cait_small\":\n",
    "    from models.cait import CaiT\n",
    "    net = CaiT(\n",
    "    image_size = size,\n",
    "    patch_size = args.patch,\n",
    "    num_classes = 10,\n",
    "    dim = int(args.dimhead),\n",
    "    depth = 6,   # depth of transformer for patch to patch attention only\n",
    "    cls_depth=2, # depth of cross attention of CLS tokens to patch\n",
    "    heads = 6,\n",
    "    mlp_dim = 256,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    layer_dropout = 0.05\n",
    ")\n",
    "elif args.net==\"swin\":\n",
    "    from models.swin import swin_t\n",
    "    net = swin_t(window_size=args.patch,\n",
    "                num_classes=10,\n",
    "                downscaling_factors=(2,2,2,1))\n",
    "\n",
    "# For Multi-GPU\n",
    "# Check if the code should be run on multiple GPUs.\n",
    "if 'cuda' in device:\n",
    "    print(device)\n",
    "    print(\"using data parallel\")\n",
    "    net = torch.nn.DataParallel(net)  # Wrap the model for parallel processing.\n",
    "    cudnn.benchmark = True  # Set the benchmark mode to true for optimized inference.\n",
    "\n",
    "# If the resume argument is set, try to load a saved checkpoint.\n",
    "if args.resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'  # Ensure the checkpoint directory exists.\n",
    "    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))  # Load the checkpoint file.\n",
    "    net.load_state_dict(checkpoint['net'])  # Load the model parameters.\n",
    "    best_acc = checkpoint['acc']  # Retrieve the best recorded accuracy.\n",
    "    start_epoch = checkpoint['epoch']  # Retrieve the epoch at which training was stopped.\n",
    "\n",
    "# Define the loss function to be used for training.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setup the optimizer based on the command line argument, with the specified learning rate.\n",
    "if args.opt == \"adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "elif args.opt == \"sgd\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=args.lr)\n",
    "\n",
    "# Setup a learning rate scheduler to adjust the learning rate over epochs.\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library for mixed precision training.\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set up the gradient scaler for automatic mixed precision (AMP).\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "# Define the train function that will be called for each epoch.\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)  # Print the current epoch number.\n",
    "    net.train()  # Set the model to training mode.\n",
    "    \n",
    "    # Initialize variables to track the loss and accuracy.\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iterate over the batched data in the trainloader.\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the correct device (GPU or CPU).\n",
    "\n",
    "        # Enable AMP autocasting for the forward pass, if it's enabled.\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            outputs = net(inputs)  # Forward pass: compute the output class probabilities.\n",
    "            loss = criterion(outputs, targets)  # Compute the loss between the outputs and labels.\n",
    "\n",
    "        # Backward pass and optimization are scaled for AMP.\n",
    "        scaler.scale(loss).backward()  # Scale the loss and compute the gradients.\n",
    "        scaler.step(optimizer)  # Call the optimizer step to update the weights.\n",
    "        scaler.update()  # Update the scale for the next iteration.\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients.\n",
    "\n",
    "        # Accumulate the loss and accuracy statistics.\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)  # Get the index of the max log-probability as the prediction.\n",
    "        total += targets.size(0)  # Update the total count of examples.\n",
    "        correct += predicted.eq(targets).sum().item()  # Update the correct prediction count.\n",
    "\n",
    "        # Call the progress bar function to print the progress.\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Return the average loss for the epoch.\n",
    "    return train_loss/(batch_idx+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for the validation or test phase.\n",
    "def test(epoch):\n",
    "    global best_acc  # Reference the global variable that tracks the best accuracy observed.\n",
    "\n",
    "    net.eval()  # Set the network to evaluation mode, which disables dropout and batch normalization effects.\n",
    "\n",
    "    # Initialize variables to track the loss and accuracy.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for efficiency and to prevent model updates.\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the batched data in the testloader.\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the correct device.\n",
    "            outputs = net(inputs)  # Compute the model's outputs.\n",
    "            loss = criterion(outputs, targets)  # Calculate the loss.\n",
    "\n",
    "            # Accumulate the loss and update accuracy metrics.\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)  # The class with the highest output value is the predicted class.\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()  # Count the number of correct predictions.\n",
    "\n",
    "            # Display the progress with the utility function.\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Calculate the accuracy of the current epoch.\n",
    "    acc = 100. * correct / total\n",
    "\n",
    "    # Check if the current accuracy is the best and save the model state if true.\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            \"model\": net.state_dict(),  # Save the model parameters.\n",
    "            \"optimizer\": optimizer.state_dict(),  # Save the optimizer state.\n",
    "            \"scaler\": scaler.state_dict()  # Save the gradient scaler state for AMP.\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')  # Create a directory for checkpoints if it doesn't exist.\n",
    "        torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))  # Save the state to a file.\n",
    "        best_acc = acc  # Update the best accuracy.\n",
    "\n",
    "    # Create a directory for logs if it does not exist and write the evaluation results.\n",
    "    os.makedirs(\"log\", exist_ok=True)\n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n",
    "    print(content)\n",
    "    with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n",
    "        appender.write(content + \"\\n\")\n",
    "\n",
    "    # Return the test loss and accuracy for this epoch.\n",
    "    return test_loss, acc\n",
    "\n",
    "# Lists to keep track of loss and accuracy over the epochs.\n",
    "list_loss = []\n",
    "list_acc = []\n",
    "\n",
    "# If Weights & Biases logging is enabled, start watching the model to log metrics.\n",
    "if usewandb:\n",
    "    wandb.watch(net)\n",
    "    \n",
    "# Move the network to the GPU if CUDA is available.\n",
    "net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5af832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the epochs from the starting epoch to the total number of epochs.\n",
    "for epoch in range(start_epoch, args.n_epochs):\n",
    "    start = time.time()  # Record the start time of the epoch.\n",
    "\n",
    "    # Call the train function defined elsewhere to perform training on the training dataset.\n",
    "    trainloss = train(epoch)\n",
    "\n",
    "    # Call the test function defined elsewhere to perform evaluation on the validation dataset.\n",
    "    val_loss, acc = test(epoch)\n",
    "    \n",
    "    # Step the scheduler to adjust the learning rate based on the number of epochs completed.\n",
    "    scheduler.step(epoch-1) # Assuming a cosine annealing learning rate schedule.\n",
    "\n",
    "    # Append the validation loss and accuracy to their respective lists for tracking.\n",
    "    list_loss.append(val_loss)\n",
    "    list_acc.append(acc)\n",
    "    \n",
    "    # If Weights & Biases logging is enabled, log the metrics for the current epoch.\n",
    "    if usewandb:\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': trainloss,\n",
    "            'val_loss': val_loss,\n",
    "            \"val_acc\": acc,\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"],  # Log the current learning rate.\n",
    "            \"epoch_time\": time.time()-start  # Log the time taken to complete the epoch.\n",
    "        })\n",
    "\n",
    "    # Write out the loss and accuracy to a CSV file after each epoch.\n",
    "    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        writer.writerow(list_loss)  # Write the list of validation losses.\n",
    "        writer.writerow(list_acc)  # Write the list of validation accuracies.\n",
    "    print(list_loss)  # Print the list of validation losses to the console.\n",
    "\n",
    "# After the training is completed, if Weights & Biases is being used, save the run data locally.\n",
    "if usewandb:\n",
    "    wandb.save(\"wandb_{}.h5\".format(args.net))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
