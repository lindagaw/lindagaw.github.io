
<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<title>CSCI 680</title>
<link rel='stylesheet' type='text/css' href='style.css'>
</head>

<body>
<h1>CSCI 680 Spring 2024: Deep Transfer Learning</h1>

<img src="https://hub.packtpub.com/wp-content/uploads/2018/03/501_Cover-Image_0.png" width="100%"  style="padding-top:14px;padding-bottom:14px">


<h2 id="toc_2">Overview</h2>

<p>Deep Transfer Learning is an advanced graduate-level course that explores the intersection of deep learning and transfer learning techniques in the field of machine learning. Specifically, this course focuses on the two major advances in the field of deep transfer learning in recent years: unsupervised domain adaptation and domain generalization. This course equips students with the knowledge and practical skills necessary to develop deep learning algorithms generalizable to new data. It delves into the practical methodologies and cutting-edge research developments in the domain of deep transfer learning.</p>

</body>

</html>

<h2 id="toc_8">Useful Links</h2>
<ul>

  <li>
    The piazza signup link is <a href="https://piazza.com/wm/spring2024/csci680">here</a>.
  </li>

  <li>
    The <a href="https://lindagaw.github.io/courses/CSCI680/CSCI680.html">course website</a> (this website) is available.
  </li>

  <li>
    The instructor's <a href="https://lindagaw.github.io/">homepage</a> is available.
  </li>

</ul>

<h2 id="toc_11">Important Dates</h2>
<table>
  <tr>
    <td><b>Agenda Item</b></td>
    <td><b>Due Date</b></td>
    <td><b>Time</b></td>
    <td><b>Location</b></td>

  </tr>

  <tr>
    <td>Final Project Report</td>
    <td>05/03</td>
    <td>23:59</td>
    <td>Blackboard</td>
  </tr>

  <tr>
    <td>Final Exam</td>
    <td>TBA</td>
    <td>TBA</td>
    <td>McGlothlin-Street Hall Room 2 (tentative)</td>
  </tr>

</table>

<h2 id="toc_3">Syllabus</h2>
<p>The <a href="./Documents/Syllabus_CSCI_680.pdf">syllabus</a> is available.




<h2 id="toc_4">Where and When</h2>

<p>Class will be held synchronously every week, including a combination of lectures and office hours. Students are encouraged to attend both the lectures and office hours each week. There will be two mandatory tests held. Students are also encouraged to reach out to the instructor(s) with any questions or concerns.</p>


<table>
  <tr>
    <td><b>Instructor</b></td>
    <td><b>Lecture Time</b></td>
    <td><b>Lecture Location</b></td>
    <td><b>Office Hours</b></td>
    <td><b>Office Location</b></td>
    <td><b>Email</b></td>
  </tr>


  <tr>
    <td>Ashley Gao</td>
    <td>T/R: 12:30-13:50</td>
    <td>McGlothlin-Street Hall Room 2</td>
    <td>W/F: 10:00-11:30</td>
    <td>McGlothlin-Street Hall 004</td>
    <td>ygao18@wm.edu</td>
  </tr>


</table>



<h2 id="toc_5">Homeworks</h2>

<p>This class will have 1 homework. Please come back to this page once it is annouced during the class that a homework is posted. The homeworks are collected using Blackboard.</p>

<p>The homeworks are <b>programming assignment</b>. They will test your knowledge on the basics of deep learning as well as deep transfer learning (unsupervised domain adaptation and domain generalization). They will not be about reviews about your paper reading.</p>

<table>
  <tr>
    <td><b>&#35;</b></td>
    <td><b>Out</b></td>
    <td><b>Due</b></td>
    <td><b>Materials</b></td>

  </tr>
  <tr>
    <td><b>1</b></td>
    <td>Feb 20</td>
    <td>Apr 20</td>
    <td><a href="Homeworks/CSCI_416_Homework_1.pdf">[TBA]</a> </td>
  </tr>

</table>



<h2 id="toc_3">Grading</h2>
<ul>
  <li>
    Homework: 25 pts
  </li>
  <li>
    Paper Presentation: 15 pts
  </li>
  <li>
    Final Exam: 25 pts
  </li>
  <li>
    Final Project: 25 pts
  </li>
  <li>
    Attendance: 10 pts
  </li>

  <p>Final letter grades will be given based on the scale detailed in the syllabus. More specifically, A >= 93% > A- >= 90% > B+ >= 87% > B >= 83% > B- >= 80% > C+ >= 77% > C >= 73% > C- >= 70% > D+ >= 67% > D >= 65% > D- >= 60% > F. Your grades may be curved at the instructor's discretion.
</ul>

<h2 id="toc_10">Schedule</h2>
<p>Note that this schedule is tentative and will be updated once a topic is covered in the lecture(s). </p>

<table width=1000>
  <tr>
    <td width="4%"><b>&#35;</b></td>
    <td width="8%"><b>Dates</b></td>
    <td width="25%"><b>Topic</b> </td>
    <td width="25%"><b>Materials</b></td>
    <td width="40%"><b>Instructor Notes</b></td>
  </tr>

  <tr>
    <td><b>0</b></td>
    <td>01/25</td>
    <td>
      <b>Lecture</b>: Class Cancelled

    </td>
    <td>
      <b>Lecture:</b> No Class <br/>
    </td>

    <td>
      The syllabus is available at <a href="./Documents/Syllabus_CSCI_680.pdf">here</a>.

    </td>

  </tr>

  <tr>
    <td><b>1</b></td>
    <td>01/30</td>
    <td>
      <b>Lecture</b>: Logistics & Introduction to Deep Transfer Learning

    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_1_Intro_DTL.pdf">[Lecture]</a> <br/>
    </td>

    <td>
      Zhu, et al (2023): <a href="https://www.youtube.com/watch?v=kYRkDd3C4gs&ab_channel=XiangYu"> Visual Domain Adaptation and Generalization </a>

    </td>

  </tr>


  <tr>
    <td><b>2</b></td>
    <td>02/01, 02/06</td>
    <td>
      <b>Lecture</b>: Linear Models & Optimization

    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_2_Linear_Regression_Optimization.pdf">[Lecture]</a> <br/>
      <b>Tutorial:</b> <a href="Tutorials/Tutorial_2_Linear_Regression.ipynb">[Tutorial]</a> <br/>

    </td>

    <td>
      Ng (2018): <a href="https://www.youtube.com/watch?v=4b4MUYve_U8&ab_channel=StanfordOnline">Linear Regression & Gradient Descent</a>
    </td>

  </tr>

  <tr>
    <td><b>3</b></td>
    <td>02/08, 02/13</td>
    <td>
      <b>Lecture</b>: Logistic Regression, Multiclass Classification

    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_3_Logistic_Regression.pdf">[Lecture]</a> <br/>
      <b>Tutorial:</b> <a href="Tutorials/Tutorial_3_Logistic_Regression.ipynb">[Tutorial]</a> <br/>

    </td>

    <td>
      Ng (2017): <a href="https://www.youtube.com/watch?v=4u81xU7BIOc&ab_channel=MachineLearningandAI">Logistic Regression</a>
    </td>

  </tr>

  <tr>
    <td><b>4</b></td>
    <td>02/15, 02/20</td>
    <td>
      <b>Lecture:</b> Multilayer Perceptrons<br/>
      <b>Tutorial:</b> MLP <br/>
    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_4_Multilayer_Perceptrons.pdf">[Lecture]</a> <br/>
      <b>Tutorial:</b> <a href="Tutorials/Tutorial_4_MLP.ipynb">[Tutorial]</a> </br>

    </td>

    <td>
      Stanford: <a href="http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/">Multilayer Perceptrons</a>
    </td>

  </tr>


</table>




<h2 id="toc_12">Final Project</h2>

<p>25% of your total mark is allocated to a final project, which will require you to apply several algorithms to a challenge problem and to write a short report analyzing the results. The final project is an individual project, meaning that you are not allowed to collaborate with others. </p>
