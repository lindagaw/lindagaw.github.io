
<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<title>CSCI 680</title>
<link rel='stylesheet' type='text/css' href='style.css'>
</head>

<body>
<h1>CSCI 680 Spring 2025: Deep Transfer Learning</h1>

<img src="https://media.licdn.com/dms/image/D4E12AQFo3qtESVmTlw/article-cover_image-shrink_720_1280/0/1714985367766?e=2147483647&v=beta&t=5NCEFf4e7nYFblUxNWHCDiaJiH2TpAXXKbiRnuSeupM" width="100%"  style="padding-top:14px;padding-bottom:14px">


<h2 id="toc_2">Overview</h2>

<p>Deep Transfer Learning is an advanced graduate-level course that explores the intersection of deep learning and transfer learning techniques in the field of machine learning. Specifically, this course focuses on the two major advances in the field of deep transfer learning in recent years: unsupervised domain adaptation and domain generalization. This course equips students with the knowledge and practical skills necessary to develop deep learning algorithms generalizable to new data. It delves into the practical methodologies and cutting-edge research developments in the domain of deep transfer learning.</p>

</body>

</html>

<h2 id="toc_8">Useful Links</h2>
<ul>

  <li>
    The <a href="https://lindagaw.github.io/courses/CSCI680/CSCI680.html">course website</a> (this website) is available.
  </li>

  <li>
    The instructor's <a href="https://lindagaw.github.io/">homepage</a> is available.
  </li>

</ul>

<h2 id="toc_11">Important Dates</h2>
<table>
  <tr>
    <td><b>Agenda Item</b></td>
    <td><b>Due Date</b></td>
    <td><b>Time</b></td>
    <td><b>Location</b></td>

  </tr>

  <tr>
    <td>Final Project Report</td>
    <td>05/13</td>
    <td>23:59</td>
    <td>Blackboard</td>
  </tr>

  <tr>
    <td>Final Exam</td>
    <td>TBA</td>
    <td>TBA</td>
    <td>Small Physics Lab 235 (tentative)</td>
  </tr>

</table>

<h2 id="toc_3">Syllabus</h2>
<p>The <a href="./Documents/Syllabus_CSCI_680.pdf">syllabus</a> is available.




<h2 id="toc_4">Where and When</h2>

<p>Class will be held synchronously every week, including a combination of lectures and office hours. Students are encouraged to attend both the lectures and office hours each week. There will be two mandatory tests held. Students are also encouraged to reach out to the instructor(s) with any questions or concerns.</p>


<table>
  <tr>
    <td><b>Instructor</b></td>
    <td><b>Lecture Time</b></td>
    <td><b>Lecture Location</b></td>
    <td><b>Office Hours</b></td>
    <td><b>Office Location</b></td>
    <td><b>Email</b></td>
  </tr>


  <tr>
    <td>Ashley Gao</td>
    <td>M/W: 14:00-15:20</td>
    <td>Small Physics Lab 235</td>
    <td>T/R: 11:00-12:30</td>
    <td>McGlothlin-Street Hall 004</td>
    <td>ygao18@wm.edu</td>
  </tr>


</table>



<h2 id="toc_5">Homework(s)</h2>

<p>This class will have 1 homework. Please come back to this page once it is annouced during the class that a homework is posted. The homeworks are collected using Blackboard.</p>

<p>The homework is a <b>programming assignment</b>. They will test your knowledge on the basics of deep learning as well as deep transfer learning (unsupervised domain adaptation and domain generalization). They will not be about reviews about your paper reading.</p>

<table>
  <tr>
    <td><b>&#35;</b></td>
    <td><b>Out</b></td>
    <td><b>Due</b></td>
    <td><b>Materials</b></td>

  </tr>
  <tr>
    <td><b>1</b></td>
    <td>Jan 21</td>
    <td>May 13</td>
    <td><a href="Homeworks/CSCI_680_Homework.pdf">[Homework]</a> </td>
  </tr>

</table>



<h2 id="toc_3">Grading</h2>
<ul>
  <li>
    Homework: 25 pts
  </li>
  <li>
    Paper Presentation: 15 pts
  </li>
  <li>
    Final Exam: 25 pts
  </li>
  <li>
    Final Project: 25 pts
  </li>
  <li>
    Attendance: 10 pts
  </li>

  <p>Final letter grades will be given based on the scale detailed in the syllabus. More specifically, A >= 93% > A- >= 90% > B+ >= 87% > B >= 83% > B- >= 80% > C+ >= 77% > C >= 73% > C- >= 70% > D+ >= 67% > D >= 65% > D- >= 60% > F. Your grades may be curved at the instructor's discretion.
</ul>

<h2 id="toc_10">Lecture Schedule</h2>
<p>Note that this schedule is tentative and will be updated once a topic is covered in the lecture(s). </p>

<table width=850>
  <tr>
    <td width="4%"><b>&#35;</b></td>
    <td width="8%"><b>Dates</b></td>
    <td width="25%"><b>Topic</b> </td>
    <td width="25%"><b>Materials</b></td>
    <td width="40%"><b>Instructor Notes</b></td>
  </tr>

<p>Suggested readings are optional; they are resources we recommend to help you understand the course material. All of the textbooks listed below are freely available online.</p>

<p>Note that this schedule is tentative and will be updated once a topic is covered in the lecture(s). </p>

<p>Bishop = <a href="https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book">Pattern Recognition and Machine Learning</a>, by Chris Bishop.<br/>
ESL = <a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">The Elements of Statistical Learning</a>, by Hastie, Tibshirani, and Friedman. <br/>
MacKay = <a href="http://www.inference.org.uk/itila/book.html">Information Theory, Inference, and Learning Algorithms</a>, by David MacKay. <br/>
Barber = <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf">Bayesian Reasoning and Machine Learning</a>, by David Barber.<br/>
MC = <a href="https://www.youtube.com/watch?v=JAf_aSIJryg&ab_channel=TheOrganicChemistryTutor">Multivariate Calculus</a>, on Youtube.<br/>



  <tr>
    <td><b>1</b></td>
    <td>01/27</td>
    <td>
      <b>Lecture</b>: Logistics & Introduction to Deep Transfer Learning
    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_1_Intro_DTL.pdf">[Lecture]</a> <br/>
    </td>

    <td>
      Zhu, et al (2023): <a href="https://www.youtube.com/watch?v=kYRkDd3C4gs&ab_channel=XiangYu"> Visual Domain Adaptation and Generalization </a>
    </td>
  </tr>
  <tr>
    <td><b>2</b></td>
    <td>01/29, 02/03, 02/05</td>
    <td>
      <b>Lecture</b>: Linear Regression, Optimization <br/>
      <b>Tutorial</b>: Linear Regressor with SGD
 
    </td>
    <td>
      <b>Lecture:</b> <a href="Lectures/Lecture_2_Linear_Regression_Optimization.pdf">[Lecture]</a> <br/>
      <b>Tutorial:</b> <a href="Tutorials/Tutorial_2_Linear_Regression.ipynb">[Tutorial]</a> <br/>
    </td>
    <td>
      Bishop: 3.1<br/>
      ESL: 3.1 - 3.2<br/>
    </td>
    </tr>

    <tr>
      <td><b>3</b></td>
      <td>02/10, 02/12, 02/17</td>
      <td>
        <b>Lecture:</b> Logistic Regression, Multiclass Classification<br/>
        <b>Tutorial:</b> Logistic Regression <br/>
  
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_3_Logistic_Regression.pdf">[Lecture]</a> <br/>
        <b>Tutorial:</b> <a href="./Tutorials/Tutorial_3_Logistic_Regression.ipynb">[Tutorial]</a> <br/>
  
      </td></td>
      <td>
        Bishop: 4.1, 4.3<br/>
        ESL: 4.1-4.2, 4.4, 11<br/>
        MC: <a href="https://www.youtube.com/watch?v=JAf_aSIJryg&ab_channel=TheOrganicChemistryTutor">Partial Derivatives - Multivariable Calculus</a> <br/>
      </td>
    </tr>

    <tr>
      <td><b>4</b></td>
      <td>02/24, 02/27</td>
      <td>
        <b>Lecture:</b> Multilayer Perceptrons<br/>
        <b>Tutorial:</b> MLP <br/>
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_4_Multilayer_Perceptrons.pdf">[Lecture]</a> <br/>
        <b>Tutorial:</b> <a href="Tutorials/Tutorial_7_MLP.ipynb">[Tutorial]</a> </br>
      </td>
      <td>
        Bishop: 5.1-5.3<br/>
      </td>
    </tr>

    <tr>
      <td><b>5</b></td>
      <td>03/03</td>
      <td>
        <b>Lecture:</b> Convolutional Neural Networks<br/>
        <b>Tutorial:</b> CNN <br/>
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_5_CNN.pdf">[Lecture]</a> <br/>
        <b>Tutorial:</b> <a href="Tutorials/Tutorial_5_CNN.ipynb">[Tutorial]</a> </br>
      </td>
      <td>
        <a href="https://www.youtube.com/watch?v=bNb2fEVKeEo&ab_channel=StanfordUniversitySchoolofEngineering">CNN</a> <br/>
      </td>
    </tr>

    <tr>
      <td><b>6</b></td>
      <td>03/03</td>
      <td>
        <b>Lecture:</b> Recurrent Neural Networks<br/>
        <b>Tutorial:</b> RNN <br/>
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_6_RNN.pdf">[Lecture]</a> <br/>
      </td>
      <td>
        <a href="https://www.youtube.com/watch?v=6niqTuYFZLQ&ab_channel=StanfordUniversitySchoolofEngineering">CNN</a> <br/>
      </td>
    </tr>

    <tr>
      <td><b>7</b></td>
      <td>03/03</td>
      <td>
        <b>Lecture:</b> Attention and Transformers<br/>
        <b>Tutorial:</b> Vision Transformers <br/>
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_7_Attention.pdf">[Lecture]</a> <br/>
        <b>Tutorial:</b> <a href="Tutorials/Tutorial_8_Vision_Transformers.py">[Tutorial]</a> </br>
      </td>
      <td>
        <a href="https://www.youtube.com/watch?v=4Bdc55j80l8&t=745s&ab_channel=TheAIHacker">CNN</a> <br/>
      </td>
    </tr>

    <tr>
      <td><b>8</b></td>
      <td>03/05</td>
      <td>
        <b>Lecture:</b> Philosophy of ML/AI<br/>
      </td>
      <td>
        <b>Lecture:</b> <a href="Lectures/Lecture_8_Philosophy_of_AI.pdf">[Lecture]</a> <br/>
      </td>
      <td>
        Gao, 2019: <a href="Documents/Personal_Statement.pdf">Personal Statement</a> <br/>
      </td>
    </tr>


</table>


<h2 id="toc_19">Final Project</h2>

<p>25% of your total mark is allocated to a final project, which will require you to apply several algorithms to a challenge problem and to write a short report analyzing the results. The final project is an individual project, meaning that you are not allowed to collaborate with others. </p>
